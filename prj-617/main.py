import functions_framework
from google.cloud import bigquery, storage
import os
import datetime
import pandas as pd
import sys
from io import BytesIO
import logging


logging.basicConfig(level=logging.INFO)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
PROJECT_ID = os.environ.get('PROJECT_ID')
DATASET_ID = os.environ.get('DATASET_ID')
TABLE_ID = os.environ.get('TABLE_ID')
BUCKET_NAME = os.environ.get('BUCKET_NAME')
GCS_PATH_SUFFIX = os.environ.get('GCS_PATH_SUFFIX', '')


def export_bq_to_gcs():
    """
    í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§: BQ -> Pandas -> GCS
    """
    # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
    if not all([PROJECT_ID, DATASET_ID, TABLE_ID, BUCKET_NAME]):
        raise ValueError('Missing required environment variables')

    # 1. íŒŒì¼ëª… ë° ê²½ë¡œ ìƒì„±
    datestamp = datetime.datetime.now().strftime("%Y%m%d")
    base_filename = f"{datestamp}_inner_page_source_data"
    csv_filename = f"{base_filename}.csv"
    excel_filename = f"{base_filename}.xlsx"
    blob_path = f"{GCS_PATH_SUFFIX.strip('/')}/" if GCS_PATH_SUFFIX else ""
    
    # 2. BigQueryì—ì„œ ë°ì´í„° ì½ê¸°
    table_path = f"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}"
    logging.info(f"ğŸ”— Reading from BigQuery: {table_path}")
    
    # read_gbqëŠ” ë°ì´í„°ê°€ í´ ê²½ìš° ë©”ëª¨ë¦¬ ì—ëŸ¬ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜
    df = pd.read_gbq(f"SELECT * FROM `{table_path}`", project_id=PROJECT_ID)
    logging.info(f"ğŸ“Š Loaded {len(df):,} rows.")

    # 3. CSV ë³€í™˜
    csv_data = df.to_csv(index=False, encoding='utf-8-sig')
    
    # 4. Excel ë³€í™˜
    excel_buffer = BytesIO()
    df.to_excel(excel_buffer, index=False, engine='openpyxl')
    excel_data = excel_buffer.getvalue()

    # 5. GCS ì—…ë¡œë“œ
    storage_client = storage.Client()
    bucket = storage_client.bucket(BUCKET_NAME)
    
    # CSV ì—…ë¡œë“œ
    csv_blob = bucket.blob(blob_path + csv_filename)
    csv_blob.upload_from_string(csv_data, content_type='text/csv; charset=utf-8')
    
    # Excel ì—…ë¡œë“œ
    excel_blob = bucket.blob(blob_path + excel_filename)
    excel_blob.upload_from_string(excel_data, content_type='application/vnd.ms-excel')

    return {"csv": csv_blob.name, "excel": excel_blob.name}


@functions_framework.http
def main_handler(request):
    """
    ì§„ì…ì (Entry Point) - ë°°í¬ ì‹œ ì´ í•¨ìˆ˜ ì´ë¦„ì„ 'ì§„ì…ì 'ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
    """
    # OPTIONS ìš”ì²­ ì²˜ë¦¬ (CORS)
    if request.method == 'OPTIONS':
        return ('', 204, {'Access-Control-Allow-Origin': '*'})

    try:
        # ë¡œì§ ì‹¤í–‰
        files = export_bq_to_gcs()
        
        logging.info("âœ… Pipeline finished successfully.")
        return {
            "status": "success",
            "files": files
        }, 200

    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ì •ë³´ ë¡œê¹…
        error_msg = f"âŒ Pipeline failed: {str(e)}"
        logging.error(error_msg, exc_info=True) # exc_infoëŠ” Traceback ì „ì²´ë¥¼ ë¡œê¹…í•©ë‹ˆë‹¤.
        
        # Schedulerê°€ ì‹¤íŒ¨ë¡œ ì¸ì‹í•˜ë„ë¡ 500 ë¦¬í„´
        return {
            "status": "failed",
            "error": str(e)
        }, 500